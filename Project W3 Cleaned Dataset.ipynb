{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f40ea48-4861-4810-8f26-d40d8c3aa840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['distance_from_home', 'distance_from_last_transaction',\n",
      "       'ratio_to_median_purchase_price', 'repeat_retailer', 'used_chip',\n",
      "       'used_pin_number', 'online_order', 'fraud'],\n",
      "      dtype='object')\n",
      "Logistic Regression Accuracy: 0.9623333333333334\n",
      "Logistic Regression Precision: 0.8801089918256131\n",
      "Logistic Regression Recall: 0.6396039603960396\n",
      "Logistic Regression F1-Score: 0.7408256880733946\n"
     ]
    }
   ],
   "source": [
    "# cleaned dataset  Logistic Regression\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Check the column names to ensure target column 'fraud' exists\n",
    "print(df.columns)\n",
    "\n",
    "# Preprocess dataset - using 'fraud' as the target column\n",
    "X = df.drop('fraud', axis=1)\n",
    "y = df['fraud']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features to improve model performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression Model\n",
    "\n",
    "# Initialize and fit Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_lr = log_model.predict(X_test_scaled)\n",
    "\n",
    "# Store metrics for Logistic Regression\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "# Output the results\n",
    "print(f'Logistic Regression Accuracy: {accuracy_lr}')\n",
    "print(f'Logistic Regression Precision: {precision_lr}')\n",
    "print(f'Logistic Regression Recall: {recall_lr}')\n",
    "print(f'Logistic Regression F1-Score: {f1_lr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9c77bb4-8777-4364-b8ef-0b129442d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9641666666666666\n",
      "SVM Precision: 0.8756476683937824\n",
      "SVM Recall: 0.6693069306930693\n",
      "SVM F1-Score: 0.7586980920314254\n"
     ]
    }
   ],
   "source": [
    "# cleaned dataset  SVM\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Preprocess dataset\n",
    "X = df.drop('fraud', axis=1)\n",
    "y = df['fraud']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SVM Model\n",
    "\n",
    "# Initialize and fit SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Store metrics for SVM\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "# Output the results\n",
    "print(f'SVM Accuracy: {accuracy_svm}')\n",
    "print(f'SVM Precision: {precision_svm}')\n",
    "print(f'SVM Recall: {recall_svm}')\n",
    "print(f'SVM F1-Score: {f1_svm}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50d2b5f3-6883-4dc0-8169-0552677f0d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.9955\n",
      "KNN Precision: 0.9818548387096774\n",
      "KNN Recall: 0.9643564356435643\n",
      "KNN F1-Score: 0.973026973026973\n"
     ]
    }
   ],
   "source": [
    "# cleaned dataset  KNN\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Preprocess dataset\n",
    "X = df.drop('fraud', axis=1)\n",
    "y = df['fraud']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# KNN Model\n",
    "\n",
    "# Initialize and fit KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Store metrics for KNN\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "\n",
    "# Output the results\n",
    "print(f'KNN Accuracy: {accuracy_knn}')\n",
    "print(f'KNN Precision: {precision_knn}')\n",
    "print(f'KNN Recall: {recall_knn}')\n",
    "print(f'KNN F1-Score: {f1_knn}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d0a029a-c081-4689-a462-e13a645a5145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9988333333333334\n",
      "Decision Tree Precision: 0.9920948616600791\n",
      "Decision Tree Recall: 0.994059405940594\n",
      "Decision Tree F1-Score: 0.9930761622156281\n"
     ]
    }
   ],
   "source": [
    "# # cleaned dataset  Decision Trees\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Preprocess dataset\n",
    "X = df.drop('fraud', axis=1)\n",
    "y = df['fraud']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Decision Tree Model\n",
    "\n",
    "# Initialize and fit Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Store metrics for Decision Tree\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "# Output the results\n",
    "print(f'Decision Tree Accuracy: {accuracy_dt}')\n",
    "print(f'Decision Tree Precision: {precision_dt}')\n",
    "print(f'Decision Tree Recall: {recall_dt}')\n",
    "print(f'Decision Tree F1-Score: {f1_dt}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "483d32df-9556-4e2f-be0a-315c7a34ac40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9995\n",
      "Random Forest Precision: 1.0\n",
      "Random Forest Recall: 0.994059405940594\n",
      "Random Forest F1-Score: 0.997020854021847\n"
     ]
    }
   ],
   "source": [
    "# cleaned dataset  Random Forest\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Preprocess dataset\n",
    "X = df.drop('fraud', axis=1)\n",
    "y = df['fraud']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Random Forest Model\n",
    "\n",
    "# Initialize and fit Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Store metrics for Random Forest\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "# Output the results\n",
    "print(f'Random Forest Accuracy: {accuracy_rf}')\n",
    "print(f'Random Forest Precision: {precision_rf}')\n",
    "print(f'Random Forest Recall: {recall_rf}')\n",
    "print(f'Random Forest F1-Score: {f1_rf}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "157e7ae4-e310-478b-b9a6-e51e8ca740ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.9991666666666666\n",
      "Gradient Boosting Precision: 1.0\n",
      "Gradient Boosting Recall: 0.9900990099009901\n",
      "Gradient Boosting F1-Score: 0.9950248756218906\n"
     ]
    }
   ],
   "source": [
    "# cleaned dataset  Gradient Boosting\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Preprocess dataset\n",
    "X = df.drop('fraud', axis=1)\n",
    "y = df['fraud']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Gradient Boosting Model\n",
    "\n",
    "# Initialize and fit Gradient Boosting model\n",
    "gbm_model = GradientBoostingClassifier()\n",
    "gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_gbm = gbm_model.predict(X_test)\n",
    "\n",
    "# Store metrics for Gradient Boosting\n",
    "accuracy_gbm = accuracy_score(y_test, y_pred_gbm)\n",
    "precision_gbm = precision_score(y_test, y_pred_gbm)\n",
    "recall_gbm = recall_score(y_test, y_pred_gbm)\n",
    "f1_gbm = f1_score(y_test, y_pred_gbm)\n",
    "\n",
    "# Output the results\n",
    "print(f'Gradient Boosting Accuracy: {accuracy_gbm}')\n",
    "print(f'Gradient Boosting Precision: {precision_gbm}')\n",
    "print(f'Gradient Boosting Recall: {recall_gbm}')\n",
    "print(f'Gradient Boosting F1-Score: {f1_gbm}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70b68014-0ea9-46c4-8ab7-33b3c7a48229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from catboost) (3.8.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "CatBoost Accuracy: 0.9986666666666667\n",
      "CatBoost Precision: 0.9960079840319361\n",
      "CatBoost Recall: 0.9881188118811881\n",
      "CatBoost F1-Score: 0.9920477137176938\n"
     ]
    }
   ],
   "source": [
    "# cleaned dataset  cat Boost\n",
    "!pip install catboost\n",
    "\n",
    "# Import necessary libraries\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Preprocess dataset\n",
    "X = df.drop('fraud', axis=1)\n",
    "y = df['fraud']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# CatBoost Model\n",
    "\n",
    "# Initialize and fit CatBoost model\n",
    "cat_model = CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, verbose=0)\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "\n",
    "# Store metrics for CatBoost\n",
    "accuracy_cat = accuracy_score(y_test, y_pred_cat)\n",
    "precision_cat = precision_score(y_test, y_pred_cat)\n",
    "recall_cat = recall_score(y_test, y_pred_cat)\n",
    "f1_cat = f1_score(y_test, y_pred_cat)\n",
    "\n",
    "# Output the results\n",
    "print(f'CatBoost Accuracy: {accuracy_cat}')\n",
    "print(f'CatBoost Precision: {precision_cat}')\n",
    "print(f'CatBoost Recall: {recall_cat}')\n",
    "print(f'CatBoost F1-Score: {f1_cat}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c5f0c66a-a7bb-4585-aca4-1f420d78179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "[LightGBM] [Info] Number of positive: 1210, number of negative: 12790\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 14000, number of used features: 7\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.086429 -> initscore=-2.358043\n",
      "[LightGBM] [Info] Start training from score -2.358043\n",
      "LightGBM Accuracy: 0.9978333333333333\n",
      "LightGBM Precision: 0.992\n",
      "LightGBM Recall: 0.9821782178217822\n",
      "LightGBM F1-Score: 0.9870646766169154\n"
     ]
    }
   ],
   "source": [
    "# cleaned dataset Light Gradient Boosting\n",
    "\n",
    "!pip install lightgbm\n",
    "# Import necessary libraries\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Preprocess dataset\n",
    "X = df.drop('fraud', axis=1)\n",
    "y = df['fraud']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# LightGBM Model\n",
    "\n",
    "# Initialize and fit LightGBM model\n",
    "lgb_model = lgb.LGBMClassifier()\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Store metrics for LightGBM\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "precision_lgb = precision_score(y_test, y_pred_lgb)\n",
    "recall_lgb = recall_score(y_test, y_pred_lgb)\n",
    "f1_lgb = f1_score(y_test, y_pred_lgb)\n",
    "\n",
    "# Output the results\n",
    "print(f'LightGBM Accuracy: {accuracy_lgb}')\n",
    "print(f'LightGBM Precision: {precision_lgb}')\n",
    "print(f'LightGBM Recall: {recall_lgb}')\n",
    "print(f'LightGBM F1-Score: {f1_lgb}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fef445fc-31e4-486d-a495-150eea8628b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "XGBoost Accuracy: 0.9985\n",
      "XGBoost Precision: 0.9940239043824701\n",
      "XGBoost Recall: 0.9881188118811881\n",
      "XGBoost F1-Score: 0.9910625620655412\n"
     ]
    }
   ],
   "source": [
    "# cleaned dataset Extreme Gradient Boosting\n",
    "\n",
    "!pip install xgboost\n",
    "# Import necessary libraries\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Preprocess dataset\n",
    "X = df.drop('fraud', axis=1)\n",
    "y = df['fraud']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# XGBoost Model\n",
    "\n",
    "# Initialize and fit XGBoost model\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Store metrics for XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Output the results\n",
    "print(f'XGBoost Accuracy: {accuracy_xgb}')\n",
    "print(f'XGBoost Precision: {precision_xgb}')\n",
    "print(f'XGBoost Recall: {recall_xgb}')\n",
    "print(f'XGBoost F1-Score: {f1_xgb}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "784e328e-75b0-439c-b257-84bcb1755681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sivad\\downloads\\jupyter\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n",
      "Epoch 1/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 446us/step - accuracy: 0.9411 - loss: 0.2010\n",
      "Epoch 2/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.9844 - loss: 0.0409\n",
      "Epoch 3/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9899 - loss: 0.0289\n",
      "Epoch 4/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.9906 - loss: 0.0291\n",
      "Epoch 5/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.9924 - loss: 0.0212\n",
      "Epoch 6/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 0.9943 - loss: 0.0169\n",
      "Epoch 7/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.9938 - loss: 0.0201\n",
      "Epoch 8/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.9959 - loss: 0.0148\n",
      "Epoch 9/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.9938 - loss: 0.0145\n",
      "Epoch 10/10\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.9971 - loss: 0.0100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step\n",
      "Neural Networks Accuracy: 0.9941666666666666\n",
      "Neural Networks Precision: 0.9501915708812261\n",
      "Neural Networks Recall: 0.9821782178217822\n",
      "Neural Networks F1-Score: 0.9659201557935735\n"
     ]
    }
   ],
   "source": [
    "# cleaned dataset Neural Networks(Deep Learning Model)\n",
    "\n",
    "!pip install tensorflow\n",
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Preprocess dataset\n",
    "X = df.drop('fraud', axis=1)\n",
    "y = df['fraud']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Neural Networks Model\n",
    "\n",
    "# Initialize and fit Neural Networks model\n",
    "input_shape = X_train_scaled.shape[1]\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(input_shape,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_nn = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# Store metrics for Neural Networks\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "precision_nn = precision_score(y_test, y_pred_nn)\n",
    "recall_nn = recall_score(y_test, y_pred_nn)\n",
    "f1_nn = f1_score(y_test, y_pred_nn)\n",
    "\n",
    "# Output the results\n",
    "print(f'Neural Networks Accuracy: {accuracy_nn}')\n",
    "print(f'Neural Networks Precision: {precision_nn}')\n",
    "print(f'Neural Networks Recall: {recall_nn}')\n",
    "print(f'Neural Networks F1-Score: {f1_nn}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c9b53fe-ac66-446f-8ee0-9d6c5ce31876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned dataset AUTO ML TPOT( TO FIND OUT THE BEST MODEL)\n",
    "\n",
    "\n",
    "#!pip install tpot\n",
    "#!pip install torch\n",
    "#!pip install ipywidgets\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "# Import necessary libraries\n",
    "#from tpot import TPOTClassifier\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "#df = pd.read_csv('C:\\\\Users\\\\sivad\\\\OneDrive\\\\Desktop\\\\project\\\\cleaned_fraud_data.csv')\n",
    "\n",
    "# Preprocess dataset\n",
    "#X = df.drop('fraud', axis=1)\n",
    "#y = df['fraud']\n",
    "\n",
    "# Split the dataset\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and fit TPOT AutoML model\n",
    "#tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\n",
    "#tpot.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "#y_pred_tpot = tpot.predict(X_test)\n",
    "#accuracy_tpot = accuracy_score(y_test, y_pred_tpot)\n",
    "#precision_tpot = precision_score(y_test, y_pred_tpot)\n",
    "#recall_tpot = recall_score(y_test, y_pred_tpot)\n",
    "#f1_tpot = f1_score(y_test, y_pred_tpot)\n",
    "\n",
    "# Output results\n",
    "#print(f'TPOT AutoML Accuracy: {accuracy_tpot}')\n",
    "#print(f'TPOT AutoML Precision: {precision_tpot}')\n",
    "#print(f'TPOT AutoML Recall: {recall_tpot}')\n",
    "#print(f'TPOT AutoML F1-Score: {f1_tpot}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "62d15464-9501-4509-be88-6fb6e0af539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model based on F1-Score is: Random Forest with a score of 0.997020854021847\n",
      "The best model based on accuracy is: Random Forest with a score of 0.9995\n",
      "The best model based on precision is: Random Forest with a score of 1.0\n",
      "The best model based on recall is: Decision Tree with a score of 0.994059405940594\n"
     ]
    }
   ],
   "source": [
    "## Define a dictionary to store the performance of each model\n",
    "model_performance = {\n",
    "    'Logistic Regression': {'accuracy': accuracy_lr, 'precision': precision_lr, 'recall': recall_lr, 'f1': f1_lr},\n",
    "    'KNN': {'accuracy': accuracy_knn, 'precision': precision_knn, 'recall': recall_knn, 'f1': f1_knn},\n",
    "    'SVM': {'accuracy': accuracy_svm, 'precision': precision_svm, 'recall': recall_svm, 'f1': f1_svm},\n",
    "    'Decision Tree': {'accuracy': accuracy_dt, 'precision': precision_dt, 'recall': recall_dt, 'f1': f1_dt},\n",
    "    'CatBoost': {'accuracy': accuracy_cat, 'precision': precision_cat, 'recall': recall_cat, 'f1': f1_cat},\n",
    "    'XGBoost': {'accuracy': accuracy_xgb, 'precision': precision_xgb, 'recall': recall_xgb, 'f1': f1_xgb},\n",
    "    'LightGBM': {'accuracy': accuracy_lgb, 'precision': precision_lgb, 'recall': recall_lgb, 'f1': f1_lgb},\n",
    "    'Random Forest': {'accuracy': accuracy_rf, 'precision': precision_rf, 'recall': recall_rf, 'f1': f1_rf},\n",
    "    'Gradient Boosting': {'accuracy': accuracy_gbm, 'precision': precision_gbm, 'recall': recall_gbm, 'f1': f1_gbm},\n",
    "    'Neural Network': {'accuracy': accuracy_nn, 'precision': precision_nn, 'recall': recall_nn, 'f1': f1_nn}\n",
    "}\n",
    "\n",
    "# Function to select the best model based on a specified metric\n",
    "def select_best_model(metric='f1'):\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for model, scores in model_performance.items():\n",
    "        if scores[metric] > best_score:\n",
    "            best_model = model\n",
    "            best_score = scores[metric]\n",
    "    \n",
    "    return best_model, best_score\n",
    "\n",
    "# Select the best model for each metric\n",
    "best_model_f1, best_score_f1 = select_best_model(metric='f1')\n",
    "best_model_accuracy, best_score_accuracy = select_best_model(metric='accuracy')\n",
    "best_model_precision, best_score_precision = select_best_model(metric='precision')\n",
    "best_model_recall, best_score_recall = select_best_model(metric='recall')\n",
    "\n",
    "# Output the best model and its performance for each metric\n",
    "print(f'The best model based on F1-Score is: {best_model_f1} with a score of {best_score_f1}')\n",
    "print(f'The best model based on accuracy is: {best_model_accuracy} with a score of {best_score_accuracy}')\n",
    "print(f'The best model based on precision is: {best_model_precision} with a score of {best_score_precision}')\n",
    "print(f'The best model based on recall is: {best_model_recall} with a score of {best_score_recall}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40505f32-8170-4a9a-a761-b064279308ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1dce10-ad6f-4f97-9d1b-b15625bb1c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
